{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30fa4074-c6b3-4196-8e91-6ade3d2fbf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from imbalanced-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from imbalanced-learn) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from imbalanced-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "601796a6-d2e8-4e16-a7f1-1185ffb0deef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 1s 16ms/step - loss: 1.0457 - accuracy: 0.5425 - val_loss: 0.8539 - val_accuracy: 0.6250\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.8922 - accuracy: 0.6237 - val_loss: 0.8181 - val_accuracy: 0.7550\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7662 - accuracy: 0.7075 - val_loss: 0.7969 - val_accuracy: 0.7350\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7560 - accuracy: 0.7200 - val_loss: 0.7817 - val_accuracy: 0.7300\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7360 - accuracy: 0.7362 - val_loss: 0.7703 - val_accuracy: 0.7250\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7219 - accuracy: 0.7425 - val_loss: 0.7613 - val_accuracy: 0.7250\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7242 - accuracy: 0.7312 - val_loss: 0.7492 - val_accuracy: 0.7250\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.7350 - val_loss: 0.7415 - val_accuracy: 0.7300\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7210 - accuracy: 0.7300 - val_loss: 0.7320 - val_accuracy: 0.7350\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6960 - accuracy: 0.7688 - val_loss: 0.7232 - val_accuracy: 0.7400\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7057 - accuracy: 0.7563 - val_loss: 0.7152 - val_accuracy: 0.7400\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7189 - accuracy: 0.7412 - val_loss: 0.7058 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.7538 - val_loss: 0.6939 - val_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6959 - accuracy: 0.7513 - val_loss: 0.6880 - val_accuracy: 0.7550\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.7625 - val_loss: 0.6795 - val_accuracy: 0.7550\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.6670 - accuracy: 0.7725 - val_loss: 0.6778 - val_accuracy: 0.7550\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6587 - accuracy: 0.7937 - val_loss: 0.6763 - val_accuracy: 0.7550\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6493 - accuracy: 0.7812 - val_loss: 0.6737 - val_accuracy: 0.7550\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6943 - accuracy: 0.7525 - val_loss: 0.6712 - val_accuracy: 0.7600\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.7725 - val_loss: 0.6669 - val_accuracy: 0.7600\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6573 - accuracy: 0.7563 - val_loss: 0.6639 - val_accuracy: 0.7650\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6646 - accuracy: 0.7788 - val_loss: 0.6605 - val_accuracy: 0.7800\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6632 - accuracy: 0.7675 - val_loss: 0.6603 - val_accuracy: 0.7700\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.7650 - val_loss: 0.6582 - val_accuracy: 0.7800\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.7862 - val_loss: 0.6547 - val_accuracy: 0.7800\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.7812 - val_loss: 0.6528 - val_accuracy: 0.7800\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6499 - accuracy: 0.7700 - val_loss: 0.6509 - val_accuracy: 0.7850\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.7775 - val_loss: 0.6512 - val_accuracy: 0.7850\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.7588 - val_loss: 0.6552 - val_accuracy: 0.7800\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.7650 - val_loss: 0.6585 - val_accuracy: 0.7800\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6386 - accuracy: 0.7788 - val_loss: 0.6576 - val_accuracy: 0.7850\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.7700 - val_loss: 0.6581 - val_accuracy: 0.7850\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.7713 - val_loss: 0.6570 - val_accuracy: 0.7800\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.7900 - val_loss: 0.6555 - val_accuracy: 0.7800\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6009 - accuracy: 0.7912 - val_loss: 0.6522 - val_accuracy: 0.7800\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6250 - accuracy: 0.7937 - val_loss: 0.6543 - val_accuracy: 0.7800\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6005 - accuracy: 0.8037 - val_loss: 0.6562 - val_accuracy: 0.7800\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.7850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78.50000262260437"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Copy dataset to avoid modifying original\n",
    "df_cleaned = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Replace 0s in specific columns with their median values (except 'Pregnancies' which can be 0)\n",
    "columns_with_zeros = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "df_cleaned[columns_with_zeros] = imputer.fit_transform(df_cleaned[columns_with_zeros])\n",
    "\n",
    "# Separate features and target\n",
    "X = df_cleaned.drop(columns=[\"Outcome\"])\n",
    "y = df_cleaned[\"Outcome\"]\n",
    "\n",
    "# Apply feature selection (SelectKBest)\n",
    "X_selected = SelectKBest(f_classif, k=8).fit_transform(X, y)\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_selected, y)\n",
    "\n",
    "# Split into train-test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define optimized MLP model\n",
    "model = Sequential([\n",
    "    Dense(64, activation=\"relu\", kernel_regularizer=l2(0.001), input_shape=(X_train.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation=\"relu\", kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation=\"relu\", kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Early Stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "test_acc_percentage = test_acc * 100\n",
    "\n",
    "test_acc_percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb16a1a-8836-4623-b889-2aacae6c8b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
